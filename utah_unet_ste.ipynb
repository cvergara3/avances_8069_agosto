{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162acdad",
   "metadata": {},
   "source": [
    "# Aplicación a datos reales - Utah FORGE\n",
    "### Datos crudos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb3e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.io.segy.segy import _read_segy\n",
    "\n",
    "SGY_DIR = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/2D_seismic_data/2D/Correlated_Shot_Gathers\"\n",
    "OUT_PATH = \"/home/pc-2/Downloads/shot_gather.png\"  \n",
    "\n",
    "def get_dt_seconds(stream):\n",
    "    \"\"\"Intenta obtener dt (s) desde header de traza o del BinaryFileHeader (microsegundos).\"\"\"\n",
    "    try:\n",
    "        us = stream.traces[0].header.sample_interval_in_ms_for_this_trace \n",
    "        if us and us > 0:\n",
    "            return float(us) * 1e-6\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        us = stream.binary_file_header.sample_interval_in_microseconds  \n",
    "        if us and us > 0:\n",
    "            return float(us) * 1e-6\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def percentile_clip(A, p=99.0):\n",
    "    a = np.percentile(np.abs(A), p)\n",
    "    return float(a) if a > 0 else float(np.max(np.abs(A)) + 1e-9)\n",
    "\n",
    "files = sorted([f for f in os.listdir(SGY_DIR) if f.lower().endswith((\".sgy\", \".segy\"))])\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"No se encontraron archivos .sgy/.segy en la carpeta.\")\n",
    "path = os.path.join(SGY_DIR, files[0])\n",
    "\n",
    "st = _read_segy(path, headonly=False)\n",
    "\n",
    "data = np.array([tr.data for tr in st.traces], dtype=np.float32)\n",
    "nrec, nt = data.shape\n",
    "\n",
    "dt_s = get_dt_seconds(st)\n",
    "t_ms = np.arange(nt, dtype=np.float32) * (dt_s * 1e3 if dt_s else 1.0)\n",
    "t_label = \"Tiempo (ms)\" if dt_s else \"Muestras\"\n",
    "\n",
    "A = percentile_clip(data, p=90.0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(\n",
    "    data.T, cmap=\"gray\", aspect=\"auto\", origin=\"upper\",\n",
    "    vmin=-A, vmax=+A,\n",
    "    extent=[0, nrec, t_ms[-1], t_ms[0]] \n",
    ")\n",
    "plt.title(f\"Shot gather: {os.path.basename(path)} (clip ±P90 |amp|)\")\n",
    "plt.xlabel(\"Receptor\")\n",
    "plt.ylabel(t_label)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"Amplitud\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(OUT_PATH, dpi=300, bbox_inches=\"tight\")\n",
    "# print(f\"✅ Figura guardada en: {OUT_PATH}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29168a",
   "metadata": {},
   "source": [
    "### Parámetros de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348dc4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/2D_seismic_data/2D/Correlated_Shot_Gathers/SGY_trim7/27_1511546140_30100_50100_20171127_150416_752_trim7.sgy\"\n",
    "from obspy import read\n",
    "\n",
    "st = read(path, format=\"SEGY\", unpack_trace_headers=True)\n",
    "tr = st[0]\n",
    "print(\"delta (s):\", tr.stats.delta)         \n",
    "print(\"sampling_rate (Hz):\", tr.stats.sampling_rate)\n",
    "print(\"npts:\", tr.stats.npts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f9714",
   "metadata": {},
   "source": [
    "### Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf636cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.io.segy.segy import _read_segy\n",
    "from obspy.signal.filter import bandpass\n",
    "from pathlib import Path\n",
    "\n",
    "# -------- CONFIG --------\n",
    "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/2D_seismic_data/2D/Correlated_Shot_Gathers/SGY_trim7\"   # <--- CAMBIA ESTO\n",
    "OUT_DIR  = \"/home/pc-2/Downloads/fig_bandpass\" \n",
    "FREQMIN, FREQMAX = 10.0, 80.0             \n",
    "PCLIP = 99.0\n",
    "BINS = 80\n",
    "SAMPLING_HZ = 1000\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def infer_sampling_hz(segy_obj, manual_fs=None):\n",
    "    if manual_fs is not None:\n",
    "        return float(manual_fs)\n",
    "    cand = []\n",
    "    h = segy_obj.traces[0].header\n",
    "    for attr in [\"sample_interval_in_ms\", \"sample_interval\", \"dt\", \"delta\", \"time_sampling\", \"trace_sampling_interval\"]:\n",
    "        if hasattr(h, attr):\n",
    "            v = getattr(h, attr)\n",
    "            if v not in (None, 0):\n",
    "                v = float(v)\n",
    "                dt = v * 1e-6 if v > 1e-3 else v\n",
    "                if dt > 0:\n",
    "                    cand.append(1.0 / dt)\n",
    "    b = getattr(segy_obj, \"binary_file_header\", None)\n",
    "    if b is not None:\n",
    "        for attr in [\"sample_interval\", \"sample_interval_in_ms\", \"interval\", \"hdt\"]:\n",
    "            if hasattr(b, attr):\n",
    "                v = getattr(b, attr)\n",
    "                if v not in (None, 0):\n",
    "                    v = float(v)\n",
    "                    dt = v * 1e-6 if v > 1e-3 else v\n",
    "                    if dt > 0:\n",
    "                        cand.append(1.0 / dt)\n",
    "    if not cand:\n",
    "        raise ValueError(\"No fue posible inferir fs; define SAMPLING_HZ.\")\n",
    "    return float(np.median(cand))\n",
    "\n",
    "def segy_to_numpy(segy_obj):\n",
    "    return np.stack([tr.data.astype(np.float64) for tr in segy_obj.traces], axis=0)  # (rec,time)\n",
    "\n",
    "def mean_spectrum_over_receivers(shot, fs_hz):\n",
    "    nrec, nt = shot.shape\n",
    "    SH = np.fft.rfft(shot, axis=1)\n",
    "    amp = np.abs(SH).mean(axis=0)\n",
    "    freqs = np.fft.rfftfreq(nt, d=1.0/fs_hz)\n",
    "    return freqs, amp\n",
    "\n",
    "def binned_spectrum(freqs, amps, nbins=80):\n",
    "    fmin, fmax = freqs[0], freqs[-1]\n",
    "    bins = np.linspace(fmin, fmax, nbins+1)\n",
    "    idx = np.digitize(freqs, bins) - 1\n",
    "    amp_binned = np.zeros(nbins, dtype=np.float64)\n",
    "    counts = np.zeros(nbins, dtype=np.int64)\n",
    "    for i, a in zip(idx, amps):\n",
    "        if 0 <= i < nbins:\n",
    "            amp_binned[i] += a\n",
    "            counts[i] += 1\n",
    "    counts[counts == 0] = 1\n",
    "    amp_binned = amp_binned / counts\n",
    "    bin_centers = 0.5*(bins[:-1] + bins[1:])\n",
    "    return bin_centers, amp_binned\n",
    "\n",
    "sgy_files = sorted(glob.glob(os.path.join(BASE_DIR, \"*.sgy\"))) + \\\n",
    "            sorted(glob.glob(os.path.join(BASE_DIR, \"*.segy\")))\n",
    "if not sgy_files:\n",
    "    raise FileNotFoundError(\"No se encontraron archivos .sgy/.segy en BASE_DIR.\")\n",
    "SHOT_PATH = sgy_files[0]\n",
    "SHOT_NAME = Path(SHOT_PATH).stem\n",
    "TAG = f\"bp_{int(FREQMIN)}-{int(FREQMAX)}Hz\"\n",
    "\n",
    "D = _read_segy(SHOT_PATH)\n",
    "fs = infer_sampling_hz(D, manual_fs=SAMPLING_HZ)\n",
    "shot = segy_to_numpy(D)   \n",
    "nrec, nt = shot.shape\n",
    "print(f\"Cargado: {SHOT_PATH}\\nShape: {shot.shape} (rec, time) | fs = {fs:.3f} Hz\")\n",
    "\n",
    "shot_f = np.empty_like(shot)\n",
    "for i in range(nrec):\n",
    "    shot_f[i] = bandpass(shot[i], freqmin=FREQMIN, freqmax=FREQMAX, df=fs,\n",
    "                         corners=4, zerophase=True)\n",
    "\n",
    "shot_diff = shot - shot_f\n",
    "\n",
    "A = np.percentile(np.abs(shot), PCLIP)\n",
    "\n",
    "fig1, axes = plt.subplots(1, 3, figsize=(16, 5), constrained_layout=True)\n",
    "im0 = axes[0].imshow(shot.T, aspect=\"auto\", cmap=\"Greys\", vmin=-0.001, vmax=0.001,\n",
    "                     extent=[0, nrec, nt, 0])\n",
    "axes[0].set_title(\"Shot original\")\n",
    "axes[0].set_xlabel(\"Receptor\"); axes[0].set_ylabel(\"Tiempo (muestras)\")\n",
    "fig1.colorbar(im0, ax=axes[0], shrink=0.8, label=\"Amplitud\")\n",
    "\n",
    "im1 = axes[1].imshow(shot_f.T, aspect=\"auto\", cmap=\"Greys\", vmin=-0.001, vmax=0.001,\n",
    "                     extent=[0, nrec, nt, 0])\n",
    "axes[1].set_title(f\"Shot filtrado (band-pass {FREQMIN}-{FREQMAX} Hz)\")\n",
    "axes[1].set_xlabel(\"Receptor\"); axes[1].set_ylabel(\"Tiempo (muestras)\")\n",
    "fig1.colorbar(im1, ax=axes[1], shrink=0.8, label=\"Amplitud\")\n",
    "\n",
    "Ad = np.percentile(np.abs(shot_diff), PCLIP)\n",
    "im2 = axes[2].imshow(shot_diff.T, aspect=\"auto\", cmap=\"Greys\", vmin=-Ad, vmax=+Ad,\n",
    "                     extent=[0, nrec, nt, 0])\n",
    "axes[2].set_title(\"Diferencia (original − filtrado)\")\n",
    "axes[2].set_xlabel(\"Receptor\"); axes[2].set_ylabel(\"Tiempo (muestras)\")\n",
    "fig1.colorbar(im2, ax=axes[2], shrink=0.8, label=\"Amplitud\")\n",
    "\n",
    "# out1 = os.path.join(OUT_DIR, f\"{SHOT_NAME}_{TAG}_comparativo\")\n",
    "# for ext in (\"png\", \"pdf\", \"svg\"):\n",
    "#     fig1.savefig(f\"{out1}.{ext}\", dpi=300, bbox_inches=\"tight\")\n",
    "# print(\"✅ Guardado:\", out1 + \".{png,pdf,svg}\")\n",
    "plt.close(fig1)\n",
    "\n",
    "freqs_o, amp_o = mean_spectrum_over_receivers(shot, fs)\n",
    "freqs_f, amp_f = mean_spectrum_over_receivers(shot_f, fs)\n",
    "nf = min(len(freqs_o), len(freqs_f))\n",
    "freqs_o, amp_o = freqs_o[:nf], amp_o[:nf]\n",
    "freqs_f, amp_f = freqs_f[:nf], amp_f[:nf]\n",
    "fbins, amp_o_b = binned_spectrum(freqs_o, amp_o, nbins=BINS)\n",
    "_,    amp_f_b = binned_spectrum(freqs_f, amp_f, nbins=BINS)\n",
    "\n",
    "fig2, ax = plt.subplots(figsize=(12, 4), constrained_layout=True)\n",
    "width = (fbins[1] - fbins[0]) * 0.45\n",
    "ax.bar(fbins - width/2, amp_o_b, width=width, alpha=0.7, label=\"Original\")\n",
    "ax.bar(fbins + width/2, amp_f_b, width=width, alpha=0.7, label=\"Filtrado\")\n",
    "ax.set_title(\"Histograma (binned) de amplitud espectral promedio\")\n",
    "ax.set_xlabel(\"Frecuencia (Hz)\"); ax.set_ylabel(\"Amplitud promedio (a.u.)\")\n",
    "ax.legend()\n",
    "\n",
    "# out2 = os.path.join(OUT_DIR, f\"{SHOT_NAME}_{TAG}_hist_binned\")\n",
    "# for ext in (\"png\", \"pdf\", \"svg\"):\n",
    "#     fig2.savefig(f\"{out2}.{ext}\", dpi=300, bbox_inches=\"tight\")\n",
    "# print(\"✅ Guardado:\", out2 + \".{png,pdf,svg}\")\n",
    "plt.close(fig2)\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(12, 4), constrained_layout=True)\n",
    "ax3.plot(freqs_o, amp_o, label=\"Original\")\n",
    "ax3.plot(freqs_f, amp_f, label=\"Filtrado\")\n",
    "ax3.set_xlim(0, min(200, freqs_o[-1]))\n",
    "ax3.set_title(\"Espectro de amplitud promedio por receptor\")\n",
    "ax3.set_xlabel(\"Frecuencia (Hz)\"); ax3.set_ylabel(\"Amplitud (a.u.)\")\n",
    "ax3.legend()\n",
    "\n",
    "# out3 = os.path.join(OUT_DIR, f\"{SHOT_NAME}_{TAG}_spectrum_line\")\n",
    "# for ext in (\"png\", \"pdf\", \"svg\"):\n",
    "#     fig3.savefig(f\"{out3}.{ext}\", dpi=300, bbox_inches=\"tight\")\n",
    "# print(\"✅ Guardado:\", out3 + \".{png,pdf,svg}\")\n",
    "plt.close(fig3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ee85f",
   "metadata": {},
   "source": [
    "### Guardar nuevos shots preprocesados .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc6cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "from obspy.io.segy.segy import _read_segy\n",
    "from obspy.signal.filter import bandpass\n",
    "import tqdm\n",
    "\n",
    "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/2D_seismic_data/2D/Correlated_Shot_Gathers/SGY_trim7\"     # <--- cambia esta ruta\n",
    "OUT_DIR  = os.path.join(BASE_DIR, \"_processed_bandpass\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "FREQMIN, FREQMAX = 10.0, 80.0          \n",
    "SAMPLING_HZ = 1000.0                        \n",
    "\n",
    "def segy_to_numpy(segy_obj):\n",
    "    \"\"\"Convierte un objeto SEG-Y a matriz (n_receptores, n_muestras)\"\"\"\n",
    "    traces = [tr.data.astype(np.float32) for tr in segy_obj.traces]\n",
    "    return np.stack(traces, axis=0)\n",
    "\n",
    "def bandpass_gather(shot, fs, fmin, fmax):\n",
    "    \"\"\"Aplica filtro pasa banda traza por traza\"\"\"\n",
    "    nrec = shot.shape[0]\n",
    "    shot_f = np.empty_like(shot)\n",
    "    for i in range(nrec):\n",
    "        shot_f[i] = bandpass(shot[i], freqmin=fmin, freqmax=fmax,\n",
    "                             df=fs, corners=4, zerophase=True)\n",
    "    return shot_f\n",
    "\n",
    "sgy_files = sorted(glob.glob(os.path.join(BASE_DIR, \"*.sgy\"))) + \\\n",
    "            sorted(glob.glob(os.path.join(BASE_DIR, \"*.segy\")))\n",
    "\n",
    "if not sgy_files:\n",
    "    raise FileNotFoundError(f\"No hay archivos .sgy en {BASE_DIR}\")\n",
    "\n",
    "for path in tqdm.tqdm(sgy_files, desc=\"Procesando gathers\"):\n",
    "    try:\n",
    "        D = _read_segy(path)\n",
    "        shot = segy_to_numpy(D)\n",
    "        shot_f = bandpass_gather(shot, SAMPLING_HZ, FREQMIN, FREQMAX)\n",
    "\n",
    "        # Nombre base\n",
    "        name = os.path.splitext(os.path.basename(path))[0]\n",
    "        out_path = os.path.join(OUT_DIR, name + \".npy\")\n",
    "        np.save(out_path, shot_f.astype(np.float32))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {path}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Procesamiento completo. Archivos guardados en:\\n{OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932c9bf",
   "metadata": {},
   "source": [
    "### Unet + STE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json, csv, re, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_msssim import SSIM\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/2D_seismic_data/2D/Correlated_Shot_Gathers/SGY_trim7/_processed_bandpass\"\n",
    "OUT_DIR  = os.path.join(BASE_DIR, \"salidas_crg_shotmask_ste_multi\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "\n",
    "EPOCHS = 700         \n",
    "BATCH  = 1\n",
    "LR     = 1e-4\n",
    "LAMBDA_SPARSITY = 0.01\n",
    "SCENARIOS = list(range(10, 100, 10)) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def norm_trace_lastaxis(x):\n",
    "    m = np.max(np.abs(x), axis=-1, keepdims=True) + 1e-6\n",
    "    return x / m\n",
    "\n",
    "def load_all_npy(base_dir):\n",
    "    files = sorted(glob.glob(os.path.join(base_dir, \"*.npy\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"No hay archivos .npy en la carpeta.\")\n",
    "    arrays, paths = [], []\n",
    "    for f in files:\n",
    "        A = np.load(f)\n",
    "        if A.ndim != 2:\n",
    "            raise ValueError(f\"{os.path.basename(f)}: se esperaba 2D, obtenido {A.shape}\")\n",
    "        r, t = A.shape\n",
    "        shot = A.astype(np.float32, copy=False) if t >= r else A.T.astype(np.float32, copy=False)\n",
    "        arrays.append(shot); paths.append(f)\n",
    "    return arrays, paths\n",
    "\n",
    "def unify_shapes(shots_list, target=None, mode=\"center\"):\n",
    "    Rs = [s.shape[0] for s in shots_list]\n",
    "    Ts = [s.shape[1] for s in shots_list]\n",
    "    if target is None:\n",
    "        H, W = min(Rs), min(Ts)\n",
    "    else:\n",
    "        H, W = target\n",
    "    def crop2d(x, H, W, mode=\"center\"):\n",
    "        r, t = x.shape\n",
    "        if r < H or t < W:\n",
    "            raise ValueError(f\"Shot {x.shape} más pequeño que el target {(H,W)}.\")\n",
    "        if mode == \"center\":\n",
    "            rs = (r - H)//2; ts = (t - W)//2\n",
    "        else:\n",
    "            rs, ts = 0, 0\n",
    "        return x[rs:rs+H, ts:ts+W].copy()\n",
    "    X = np.stack([crop2d(s, H, W, mode=mode) for s in shots_list], 0)\n",
    "    return X, (H, W)\n",
    "\n",
    "def crop_ST_mult8(arr):\n",
    "    H, S, T = arr.shape\n",
    "    S8, T8 = (S // 8) * 8, (T // 8) * 8\n",
    "    if S8 != S or T8 != T:\n",
    "        arr = arr[:, :S8, :T8].copy()\n",
    "    return arr\n",
    "\n",
    "def save_np(path, arr):\n",
    "    np.save(path, arr)\n",
    "\n",
    "print(\">>> Cargando .npy ...\")\n",
    "shots_list, file_list = load_all_npy(BASE_DIR) \n",
    "N = len(shots_list)\n",
    "print(f\">>> Cargados {N} shots .npy\")\n",
    "\n",
    "gathers_shot, (Hc, Wc) = unify_shapes(shots_list, target=None, mode=\"center\")\n",
    "H8, W8 = (Hc // 8) * 8, (Wc // 8) * 8\n",
    "if (H8 != Hc) or (W8 != Wc):\n",
    "    gathers_shot = np.ascontiguousarray(gathers_shot[:, :H8, :W8])\n",
    "    Hc, Wc = H8, W8\n",
    "assert Hc % 8 == 0 and Wc % 8 == 0\n",
    "\n",
    "gathers_shot = norm_trace_lastaxis(gathers_shot).astype(np.float32)\n",
    "\n",
    "CRG_all = np.transpose(gathers_shot, (1, 0, 2)).copy()\n",
    "H, S, T = CRG_all.shape\n",
    "print(f\">>> CRG_all: (H={H}, S={S}, T={T})\")\n",
    "\n",
    "idx_rec = np.arange(H)\n",
    "idx_tr, idx_te = train_test_split(idx_rec, test_size=0.2, random_state=GLOBAL_SEED, shuffle=True)\n",
    "CRG_tr, CRG_te = CRG_all[idx_tr], CRG_all[idx_te]\n",
    "\n",
    "CRG_all = crop_ST_mult8(CRG_all)\n",
    "CRG_tr  = crop_ST_mult8(CRG_tr)\n",
    "CRG_te  = crop_ST_mult8(CRG_te)\n",
    "H_all, S_all, T_all = CRG_all.shape\n",
    "H_tr,  S_tr,  T_tr  = CRG_tr.shape\n",
    "H_te,  S_te,  T_te  = CRG_te.shape\n",
    "assert S_tr == S_all == S_te and T_tr == T_all == T_te\n",
    "print(\">>> Shapes tras hotfix:\",\n",
    "      \"CRG_all\", CRG_all.shape,\n",
    "      \"CRG_tr\",  CRG_tr.shape,\n",
    "      \"CRG_te\",  CRG_te.shape)\n",
    "\n",
    "class UNet2DFull(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def blk(cin, cout):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 3, padding=1),\n",
    "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True),\n",
    "                nn.Conv2d(cout, cout, 3, padding=1),\n",
    "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True)\n",
    "            )\n",
    "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2,2)\n",
    "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2,2)\n",
    "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2,2)\n",
    "        self.bott = blk(256,512)\n",
    "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
    "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
    "        self.u1 = nn.ConvTranspose2d(128, 64,2,2); self.d1 = blk(128, 64)\n",
    "        self.out = nn.Conv2d(64,1,1)\n",
    "    def forward(self,x):\n",
    "        e1=self.e1(x); p1=self.p1(e1)\n",
    "        e2=self.e2(p1); p2=self.p2(e2)\n",
    "        e3=self.e3(p2); p3=self.p3(e3)\n",
    "        b=self.bott(p3)\n",
    "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
    "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
    "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
    "        return torch.tanh(self.out(d1))\n",
    "    @staticmethod\n",
    "    def crop(a,b):\n",
    "        _,_,h,w=b.shape; _,_,H,W=a.shape\n",
    "        dh,dw=(H-h)//2,(W-w)//2\n",
    "        return a[:,:,dh:dh+h, dw:dw+w]\n",
    "\n",
    "class BinaryShotMaskSTE(nn.Module):\n",
    "    def __init__(self, n_shots, init_keep_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.n_shots = int(n_shots)\n",
    "        init_keep_prob = float(np.clip(init_keep_prob, 1e-3, 1-1e-3))\n",
    "        init_logit = np.log(init_keep_prob/(1-init_keep_prob))\n",
    "        self.logits = nn.Parameter(torch.full((self.n_shots,), float(init_logit)))\n",
    "        self.frac_remove = 0.5\n",
    "    def set_frac_remove(self, frac):\n",
    "        self.frac_remove = float(np.clip(frac, 0.0, 1.0))\n",
    "    def forward(self, x):\n",
    "        assert x.dim()==4 and x.shape[2]==self.n_shots, f\"Esperaba S={self.n_shots}, got {x.shape}\"\n",
    "        probs = torch.sigmoid(self.logits)                 # (S,)\n",
    "        K = int(round(self.frac_remove * self.n_shots))\n",
    "        if K > 0:\n",
    "            idx_del = torch.topk(probs, K, largest=False).indices\n",
    "            hard = torch.ones_like(probs); hard[idx_del] = 0.0\n",
    "        else:\n",
    "            hard = torch.ones_like(probs)\n",
    "        ste_mask = hard + probs - probs.detach()           # STE\n",
    "        x_masked = x * ste_mask.view(1,1,self.n_shots,1)\n",
    "        return x_masked, probs, hard\n",
    "    @torch.no_grad()\n",
    "    def hard_indices_removed(self):\n",
    "        probs = torch.sigmoid(self.logits)\n",
    "        K = int(round(self.frac_remove * self.n_shots))\n",
    "        if K <= 0: return np.array([], dtype=int)\n",
    "        idx_del = torch.topk(probs, K, largest=False).indices\n",
    "        return idx_del.cpu().numpy()\n",
    "\n",
    "def train_quick(CRG_tr, pct, epochs=EPOCHS, batch=BATCH, lr=LR, lambda_sp=LAMBDA_SPARSITY):\n",
    "    H, S, T = CRG_tr.shape\n",
    "    assert S % 8 == 0 and T % 8 == 0, f\"(S,T)=({S},{T}) deben ser múltiplos de 8\"\n",
    "    target_keep = 1.0 - (pct/100.0)\n",
    "\n",
    "    Xt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device) \n",
    "    loader = DataLoader(TensorDataset(Xt, Xt), batch_size=batch, shuffle=True)\n",
    "\n",
    "    model = UNet2DFull().to(device)\n",
    "    mask_layer = BinaryShotMaskSTE(n_shots=S, init_keep_prob=target_keep).to(device)\n",
    "    mask_layer.set_frac_remove(pct/100.0)\n",
    "\n",
    "    opt = torch.optim.Adam([\n",
    "        {\"params\": model.parameters(), \"lr\": lr},\n",
    "        {\"params\": mask_layer.parameters(), \"lr\": lr}\n",
    "    ])\n",
    "    crit = SSIM(data_range=2.0, size_average=True, channel=1)\n",
    "\n",
    "    loss_hist = []\n",
    "    model.train()\n",
    "    for ep in range(1, epochs+1):\n",
    "        run = 0.0\n",
    "        for xb, yb in loader:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            xb_masked, probs, hard = mask_layer(xb)\n",
    "            yp = model(xb_masked)\n",
    "            loss_rec = 1.0 - crit(yp, yb)\n",
    "            keep_mean = torch.sigmoid(mask_layer.logits).mean()\n",
    "            loss_sp = (keep_mean - target_keep) ** 2\n",
    "            loss = loss_rec + lambda_sp * loss_sp\n",
    "            loss.backward(); opt.step()\n",
    "            run += float(loss.item())\n",
    "        loss_hist.append(run / len(loader))\n",
    "        print(f\"[PCT={pct:02d} | E{ep:02d}] loss={loss_hist[-1]:.4f} | keep_mean≈{float(keep_mean):.3f}\")\n",
    "    return model, mask_layer, loss_hist\n",
    "\n",
    "def eval_removed_only(model, CRG_te, removed_idx, binf=4):\n",
    "    if len(removed_idx) == 0:\n",
    "        return {\"MSE\": None, \"PSNR\": None, \"SSIM\": None, \"SNR\": None}\n",
    "    model.eval()\n",
    "    Htot, S, T = CRG_te.shape\n",
    "    MSE, PSNR, SSIMg, SNR = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for i0 in range(0, Htot, binf):\n",
    "            i1 = min(i0+binf, Htot)\n",
    "            xb_cpu = CRG_te[i0:i1].copy()\n",
    "            xb_cpu[:, removed_idx, :] = 0.0\n",
    "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
    "            yp = model(xb).squeeze(1).cpu().numpy()\n",
    "            yt = CRG_te[i0:i1]\n",
    "            for b in range(yp.shape[0]):\n",
    "                ypn = yp[b, removed_idx]\n",
    "                ytn = yt[b, removed_idx]\n",
    "                mse = np.mean((ytn - ypn)**2)\n",
    "                amp = np.ptp(ytn) + 1e-8\n",
    "                psn = 20*np.log10(amp / (np.sqrt(mse + 1e-12))) if mse > 0 else float('inf')\n",
    "                ssi = np.mean([ssim(ytn[j], ypn[j], data_range=2) for j in range(ytn.shape[0])])\n",
    "                snr = 10*np.log10((np.mean(ytn**2)+1e-12)/(mse+1e-12))\n",
    "                MSE.append(mse); PSNR.append(psn); SSIMg.append(ssi); SNR.append(snr)\n",
    "    mean = lambda v: float(np.mean(v)) if len(v) else None\n",
    "    return {\"MSE\": mean(MSE), \"PSNR\": mean(PSNR), \"SSIM\": mean(SSIMg), \"SNR\": mean(SNR)}\n",
    "\n",
    "def save_mask_bars_and_array(removed_idx, S, save_stub, title=None, height=40):\n",
    "    mask = np.ones(S, dtype=np.float32); mask[removed_idx] = 0.0\n",
    "    img = np.ones((height, S), dtype=np.float32); img[:, mask == 0] = 0.0\n",
    "    fig = plt.figure(figsize=(12, 2.2))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.imshow(img, cmap=\"gray\", aspect=\"auto\", origin=\"upper\", vmin=0, vmax=1)\n",
    "    ax.set_yticks([]); ax.set_xlabel(\"Shot (índice)\")\n",
    "    ax.set_title(title if title else \"Máscara de shots (1 keep / 0 removed)\")\n",
    "    fig.tight_layout(); fig.savefig(save_stub + \"_mask_bars.png\", dpi=140); plt.close(fig)\n",
    "    save_np(save_stub + \"_mask_bars.npy\", img)\n",
    "    return img\n",
    "\n",
    "def viz_one_shot_and_arrays(model, removed_idx, CRG_all, shot_idx, save_dir, stub, vmin=-1, vmax=1, binf=4):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    Htot, S, T = CRG_all.shape\n",
    "    pred = np.zeros((Htot, T), dtype=np.float32)\n",
    "    real = CRG_all[:, shot_idx, :].copy()\n",
    "    with torch.no_grad():\n",
    "        for i0 in range(0, Htot, binf):\n",
    "            i1 = min(i0+binf, Htot)\n",
    "            xb_cpu = CRG_all[i0:i1].copy()\n",
    "            if len(removed_idx) > 0:\n",
    "                xb_cpu[:, removed_idx, :] = 0.0\n",
    "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
    "            yb = model(xb).squeeze(1).cpu().numpy()\n",
    "            pred[i0:i1, :] = yb[:, shot_idx, :]\n",
    "    err = np.abs(pred - real)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 4.2))\n",
    "    ax1 = fig.add_subplot(1,3,1); im0 = ax1.imshow(pred.T, cmap='gray', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title(f\"Predicho — Shot {shot_idx}\"); ax1.set_xlabel(\"Receptor\"); ax1.set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im0, ax=ax1, fraction=0.046, pad=0.04)\n",
    "    ax2 = fig.add_subplot(1,3,2); im1 = ax2.imshow(real.T, cmap='gray', aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title(f\"Real — Shot {shot_idx}\"); ax2.set_xlabel(\"Receptor\"); ax2.set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im1, ax=ax2, fraction=0.046, pad=0.04)\n",
    "    ax3 = fig.add_subplot(1,3,3); im2 = ax3.imshow(err.T, cmap='inferno', aspect='auto')\n",
    "    ax3.set_title(\"Error absoluto\"); ax3.set_xlabel(\"Receptor\"); ax3.set_ylabel(\"Tiempo\")\n",
    "    fig.colorbar(im2, ax=ax3, fraction=0.046, pad=0.04)\n",
    "    fig.tight_layout(); fig.savefig(os.path.join(save_dir, f\"{stub}_maps.png\"), dpi=140); plt.close(fig)\n",
    "\n",
    "    recs = np.linspace(0, pred.shape[0]-1, num=3, dtype=int)\n",
    "    t = np.arange(pred.shape[1])\n",
    "    fig2 = plt.figure(figsize=(12,3.6))\n",
    "    for k, r in enumerate(recs):\n",
    "        ax = fig2.add_subplot(1,3,k+1)\n",
    "        ax.plot(t, real[r], label=\"Real\", linewidth=1.2)\n",
    "        ax.plot(t, pred[r], label=\"Predicho\", linewidth=1.0)\n",
    "        ax.set_title(f\"Rec {r}\"); ax.set_xlabel(\"Tiempo\"); ax.set_ylabel(\"Amp\"); ax.grid(True)\n",
    "        if k==0: ax.legend()\n",
    "    fig2.tight_layout(); fig2.savefig(os.path.join(save_dir, f\"{stub}_traces.png\"), dpi=140); plt.close(fig2)\n",
    "\n",
    "    save_np(os.path.join(save_dir, f\"{stub}_pred.npy\"), pred)\n",
    "    save_np(os.path.join(save_dir, f\"{stub}_real.npy\"), real)\n",
    "    save_np(os.path.join(save_dir, f\"{stub}_err.npy\"),  err)\n",
    "    save_np(os.path.join(save_dir, f\"{stub}_traces_idx.npy\"), recs)\n",
    "\n",
    "all_loss_hist = {}     \n",
    "metrics_rows = []        \n",
    "print(\">>> Ejecutando escenarios:\", SCENARIOS)\n",
    "\n",
    "for PCT in SCENARIOS:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\">>> Entrenando escenario {PCT}% shots eliminados\")\n",
    "    sc_dir = os.path.join(OUT_DIR, f\"pct_{PCT:02d}\")\n",
    "    os.makedirs(sc_dir, exist_ok=True)\n",
    "\n",
    "    model, mask_layer, loss_hist = train_quick(CRG_tr, pct=PCT)\n",
    "    all_loss_hist[PCT] = loss_hist\n",
    "    save_np(os.path.join(sc_dir, \"loss_hist.npy\"), np.array(loss_hist, dtype=np.float32))\n",
    "\n",
    "    removed_idx = mask_layer.hard_indices_removed()\n",
    "    S_tot = CRG_all.shape[1]\n",
    "    print(f\">>> Shots eliminados (duros): {len(removed_idx)} de {S_tot}\")\n",
    "\n",
    "    mask_stub = os.path.join(sc_dir, \"mask\")\n",
    "    _ = save_mask_bars_and_array(removed_idx, S_tot, mask_stub,\n",
    "                                 title=f\"Máscara — {PCT}% eliminados\")\n",
    "    save_np(os.path.join(sc_dir, \"removed_idx.npy\"), removed_idx.astype(np.int32))\n",
    "\n",
    "    metrics = eval_removed_only(model, CRG_te, removed_idx, binf=4)\n",
    "    with open(os.path.join(sc_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(\">>> Métricas (solo shots eliminados en TEST):\", metrics)\n",
    "\n",
    "    for s in removed_idx[:2]:\n",
    "        viz_one_shot_and_arrays(model, removed_idx, CRG_all, s,\n",
    "                                save_dir=sc_dir, stub=f\"shot_{s}\")\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(range(1,len(loss_hist)+1), loss_hist)\n",
    "    plt.title(f\"Pérdida (1-SSIM + λ·sparsity) — {PCT}%\")\n",
    "    plt.xlabel(\"Época\"); plt.ylabel(\"Loss\"); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(sc_dir, f\"loss_curve_{PCT:02d}.png\"), dpi=140); plt.close()\n",
    "\n",
    "    metrics_rows.append({\n",
    "        \"pct_removed\": PCT,\n",
    "        \"num_removed\": int(len(removed_idx)),\n",
    "        \"S_total\": int(S_tot),\n",
    "        \"MSE\": metrics[\"MSE\"],\n",
    "        \"PSNR\": metrics[\"PSNR\"],\n",
    "        \"SSIM\": metrics[\"SSIM\"],\n",
    "        \"SNR\": metrics[\"SNR\"]\n",
    "    })\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "for PCT in SCENARIOS:\n",
    "    plt.plot(range(1, len(all_loss_hist[PCT])+1), all_loss_hist[PCT], label=f\"{PCT}%\")\n",
    "plt.title(\"Curvas de pérdida por escenario (1-SSIM + λ·sparsity)\")\n",
    "plt.xlabel(\"Época\"); plt.ylabel(\"Loss\"); plt.grid(True)\n",
    "plt.legend(ncol=3, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"loss_curves_all.png\"), dpi=160)\n",
    "plt.close()\n",
    "\n",
    "np.save(os.path.join(OUT_DIR, \"all_loss_hist.npy\"), \n",
    "        np.array([ (pct, np.array(all_loss_hist[pct], dtype=np.float32)) for pct in SCENARIOS ], dtype=object),\n",
    "        allow_pickle=True)\n",
    "\n",
    "csv_path = os.path.join(OUT_DIR, \"metrics_by_pct.csv\")\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=[\"pct_removed\",\"num_removed\",\"S_total\",\"MSE\",\"PSNR\",\"SSIM\",\"SNR\"])\n",
    "    w.writeheader(); w.writerows(metrics_rows)\n",
    "\n",
    "print(\"\\n>>> FIN. Salidas en:\", OUT_DIR)\n",
    "print(\" - loss_curves_all.png\")\n",
    "print(\" - metrics_by_pct.csv\")\n",
    "print(\" - pct_xx/* (pérdidas, máscara PNG/NPY, índices, métricas, preds/real/err)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a8200f",
   "metadata": {},
   "source": [
    "### Imprimir métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"/home/pc-2/Documents/CAVE_minciencias/utah_model/2D_seismic_data/2D/Correlated_Shot_Gathers/SGY_trim7/_processed_bandpass/salidas_crg_shotmask_ste_all_equal_quick\")\n",
    "\n",
    "metric_files = sorted(BASE_DIR.glob(\"pct_*/metrics_removed_only.npz\"))\n",
    "\n",
    "if not metric_files:\n",
    "    raise FileNotFoundError(\"No se encontraron archivos metrics_removed_only.npz dentro de pct_*\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "for f in metric_files:\n",
    "    pct = f.parent.name.replace(\"pct_\", \"\")\n",
    "    data = np.load(f)\n",
    "    metrics = {k: float(v) if np.ndim(v) == 0 else float(np.mean(v)) for k, v in data.items()}\n",
    "    metrics[\"pct_remove\"] = int(pct)\n",
    "    rows.append(metrics)\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"pct_remove\").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n===== Métricas por porcentaje de submuestreo =====\")\n",
    "print(df.to_string(index=False, float_format=\"%.6f\"))\n",
    "\n",
    "OUT_CSV = BASE_DIR / \"resumen_metricas_removed_only.csv\"\n",
    "df.to_csv(OUT_CSV, index=False, float_format=\"%.6f\")\n",
    "print(f\"\\n✅ Resumen guardado en: {OUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utah_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
