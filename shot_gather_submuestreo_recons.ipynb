{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f668e3",
   "metadata": {},
   "source": [
    "### Codigo final submuestro shot gathers - random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Cargando archivos...\n",
      ">>> Cargados 512 shots.\n",
      ">>> Datos preparados (CRG, normalización, split).\n",
      ">>> Escenario 10%: preparando datos...\n",
      ">>> Escenario 10%: entrenando (40 épocas)...\n",
      ">>> Escenario 10%: inferencia y guardado de figuras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79537/3950152758.py:204: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Escenario 20%: preparando datos...\n",
      ">>> Escenario 20%: entrenando (40 épocas)...\n",
      ">>> Escenario 20%: inferencia y guardado de figuras...\n",
      ">>> Escenario 30%: preparando datos...\n",
      ">>> Escenario 30%: entrenando (40 épocas)...\n",
      ">>> Escenario 30%: inferencia y guardado de figuras...\n",
      ">>> Escenario 40%: preparando datos...\n",
      ">>> Escenario 40%: entrenando (40 épocas)...\n",
      ">>> Escenario 40%: inferencia y guardado de figuras...\n",
      ">>> Escenario 50%: preparando datos...\n",
      ">>> Escenario 50%: entrenando (40 épocas)...\n",
      ">>> Escenario 50%: inferencia y guardado de figuras...\n",
      ">>> Escenario 60%: preparando datos...\n",
      ">>> Escenario 60%: entrenando (40 épocas)...\n",
      ">>> Escenario 60%: inferencia y guardado de figuras...\n",
      ">>> Escenario 70%: preparando datos...\n",
      ">>> Escenario 70%: entrenando (40 épocas)...\n",
      ">>> Escenario 70%: inferencia y guardado de figuras...\n",
      ">>> Escenario 80%: preparando datos...\n",
      ">>> Escenario 80%: entrenando (40 épocas)...\n",
      ">>> Escenario 80%: inferencia y guardado de figuras...\n",
      ">>> Escenario 90%: preparando datos...\n",
      ">>> Escenario 90%: entrenando (40 épocas)...\n",
      ">>> Escenario 90%: inferencia y guardado de figuras...\n",
      ">>> Guardando gráfico de pérdidas (todos los escenarios)...\n",
      ">>> Listo. Figuras y tabla en: /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg\n",
      ">>> CSV de métricas: /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg/metrics_removed_shots_10_90.csv\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob, numpy as np\n",
    "from obspy.io.segy.segy import _read_segy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_msssim import SSIM\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3\"\n",
    "OUT_DIR  = os.path.join(BASE_DIR, \"salidas_crg\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "H, W = 512, 4096              \n",
    "BATCH = 1\n",
    "EPOCHS = 40\n",
    "LR = 1e-4\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "SCENARIOS = [10,20,30,40,50,60,70,80,90]\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "\n",
    "def norm_trace_lastaxis(x):  \n",
    "    m = np.max(np.abs(x), axis=-1, keepdims=True) + 1e-6\n",
    "    return x / m\n",
    "\n",
    "def crop_to_mult8_2d(arr):\n",
    "    \"\"\"Recorta 2D en ejes (S,T) a múltiplos de 8 (sin alterar receptores).\"\"\"\n",
    "    S, T = arr.shape[-2], arr.shape[-1]\n",
    "    S8, T8 = (S // 8) * 8, (T // 8) * 8\n",
    "    if S8 != S or T8 != T:\n",
    "        arr = arr[..., :S8, :T8].copy()\n",
    "    return arr\n",
    "\n",
    "def check_divisible_by_8(h, w): \n",
    "    for val, nm in [(h, \"H(shots)\"), (w, \"W(time)\")]:\n",
    "        assert val % 8 == 0, f\"{nm} debe ser múltiplo de 8 para U-Net: {val}\"\n",
    "\n",
    "def tag(fname):\n",
    "    m = re.search(r'shot_(y\\d{2})_', os.path.basename(fname).lower())\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def load_all(base_dir):\n",
    "    pats = [\"shot_y0[1-8]_*.sgy\", \"shot_y0[1-8]_*.segy\"]\n",
    "    files = sorted(sum([glob.glob(os.path.join(base_dir, p)) for p in pats], []))\n",
    "    files = [f for f in files if tag(f) is not None]\n",
    "    arrs = []\n",
    "    for f in files:\n",
    "        st = _read_segy(f, headonly=False)\n",
    "        A = np.array([tr.data for tr in st.traces], dtype=np.float32) \n",
    "        arrs.append(A)\n",
    "    return np.stack(arrs, 0), files  \n",
    "\n",
    "class UNet2DFull(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def blk(cin, cout):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 3, padding=1),\n",
    "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True),\n",
    "                nn.Conv2d(cout, cout, 3, padding=1),\n",
    "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True)\n",
    "            )\n",
    "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2,2)\n",
    "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2,2)\n",
    "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2,2)\n",
    "        self.bott = blk(256,512)\n",
    "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
    "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
    "        self.u1 = nn.ConvTranspose2d(128, 64,2,2); self.d1 = blk(128, 64)\n",
    "        self.out = nn.Conv2d(64,1,1)\n",
    "    def forward(self,x):\n",
    "        e1=self.e1(x); p1=self.p1(e1)\n",
    "        e2=self.e2(p1); p2=self.p2(e2)\n",
    "        e3=self.e3(p2); p3=self.p3(e3)\n",
    "        b=self.bott(p3)\n",
    "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
    "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
    "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
    "        return torch.tanh(self.out(d1))\n",
    "    @staticmethod\n",
    "    def crop(a,b):\n",
    "        _,_,h,w=b.shape; _,_,H,W=a.shape\n",
    "        dh,dw=(H-h)//2,(W-w)//2\n",
    "        return a[:,:,dh:dh+h, dw:dw+w]\n",
    "\n",
    "def count_params(model): return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\">>> Cargando archivos...\")\n",
    "gathers_shot, file_list = load_all(BASE_DIR)          \n",
    "print(f\">>> Cargados {len(file_list)} shots.\")\n",
    "\n",
    "assert gathers_shot.shape[1] >= H and gathers_shot.shape[2] >= W, \"Dimensiones < H/W\"\n",
    "gathers_shot = gathers_shot[:, :H, :W].copy()\n",
    "\n",
    "CRG_all = np.transpose(gathers_shot, (1, 0, 2)).copy()\n",
    "CRG_all = norm_trace_lastaxis(CRG_all)\n",
    "CRG_all = crop_to_mult8_2d(CRG_all)\n",
    "S8, T8 = CRG_all.shape[1], CRG_all.shape[2]\n",
    "check_divisible_by_8(S8, T8)\n",
    "\n",
    "idx_rec = np.arange(CRG_all.shape[0])\n",
    "idx_tr, idx_te = train_test_split(idx_rec, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(\">>> Datos preparados (CRG, normalización, split).\")\n",
    "\n",
    "def make_subsample_split(CRG_all, idx_tr, idx_te, pct, seed_base=1000):\n",
    "    \"\"\"\n",
    "    Aplica submuestreo global de shots (mismo subconjunto en todos los CRG)\n",
    "    y retorna Xtr, Xte, Ytr, Yte, shots_eliminados (set), global_removed (np.array ordenado).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed_base + pct)\n",
    "    Htot, S, T = CRG_all.shape\n",
    "    nremove = int(round(pct/100.0 * S))\n",
    "    global_removed = np.sort(rng.choice(S, size=nremove, replace=False)) if nremove > 0 else np.array([], dtype=int)\n",
    "    shots_eliminados = set(global_removed.tolist())\n",
    "\n",
    "    CRG_tr = CRG_all[idx_tr]  \n",
    "    CRG_te = CRG_all[idx_te] \n",
    "\n",
    "    Xtr = CRG_tr.copy()\n",
    "    Xte = CRG_te.copy()\n",
    "    if nremove > 0:\n",
    "        Xtr[:, global_removed, :] = 0.0\n",
    "        Xte[:, global_removed, :] = 0.0\n",
    "\n",
    "    Ytr = CRG_tr\n",
    "    Yte = CRG_te\n",
    "    return Xtr, Xte, Ytr, Yte, shots_eliminados, global_removed\n",
    "\n",
    "def train_unet_on_crg(Xtr, Ytr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR):\n",
    "    \"\"\"\n",
    "    Entrena U-Net (1-SSIM) sobre CRG submuestreados. Devuelve modelo y loss_hist.\n",
    "    Silencioso (sin prints por época).\n",
    "    \"\"\"\n",
    "    Xt = torch.from_numpy(Xtr).unsqueeze(1).to(device)\n",
    "    Yt = torch.from_numpy(Ytr).unsqueeze(1).to(device)\n",
    "\n",
    "    loader = DataLoader(TensorDataset(Xt, Yt), batch_size=batch_size, shuffle=True)\n",
    "    model = UNet2DFull().to(device)\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    crit  = SSIM(data_range=2.0, size_average=True, channel=1)\n",
    "\n",
    "    loss_hist = []\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        run = 0.0\n",
    "        for xb, yb in loader:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            yp = model(xb)\n",
    "            loss = 1 - crit(yp, yb)\n",
    "            loss.backward(); opt.step()\n",
    "            run += loss.item()\n",
    "        ep_loss = run / len(loader)\n",
    "        loss_hist.append(ep_loss)\n",
    "    return model, loss_hist\n",
    "\n",
    "def viz_shot_real_vs_pred_minibatch(model, CRG_all, shots_eliminados, shot_idx,\n",
    "                                    save_dir, file_stub, vmin=-1, vmax=1, binf=2):\n",
    "    \"\"\"\n",
    "    Predice por mini-lotes de receptores y guarda: Predicho vs Real + Error (maps) y 3 trazas (traces).\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    Htot, S, T = CRG_all.shape\n",
    "    pred_shot = np.zeros((Htot, T), dtype=np.float32)\n",
    "    real_shot = CRG_all[:, shot_idx, :].copy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i0 in range(0, Htot, binf):\n",
    "            i1 = min(i0 + binf, Htot)\n",
    "            xb_cpu = CRG_all[i0:i1].copy()             \n",
    "            if len(shots_eliminados) > 0:\n",
    "                xb_cpu[:, list(shots_eliminados), :] = 0.0\n",
    "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device, non_blocking=True) \n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                yb = model(xb).squeeze(1).float().cpu().numpy()                     \n",
    "            pred_shot[i0:i1, :] = yb[:, shot_idx, :]\n",
    "            del xb, yb\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    err = np.abs(pred_shot - real_shot)\n",
    "    fig1 = plt.figure(figsize=(18, 5))\n",
    "    ax1 = fig1.add_subplot(1,3,1)\n",
    "    im0 = ax1.imshow(pred_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title(f\"Predicho — Shot {shot_idx}\")\n",
    "    ax1.set_xlabel(\"Receptor\"); ax1.set_ylabel(\"Tiempo\"); fig1.colorbar(im0, ax=ax1, fraction=0.046, pad=0.04)\n",
    "\n",
    "    ax2 = fig1.add_subplot(1,3,2)\n",
    "    im1 = ax2.imshow(real_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title(f\"Real — Shot {shot_idx}\")\n",
    "    ax2.set_xlabel(\"Receptor\"); ax2.set_ylabel(\"Tiempo\"); fig1.colorbar(im1, ax=ax2, fraction=0.046, pad=0.04)\n",
    "\n",
    "    ax3 = fig1.add_subplot(1,3,3)\n",
    "    im2 = ax3.imshow(err.T, cmap='inferno', aspect='auto', origin='upper')\n",
    "    ax3.set_title(\"Error absoluto\")\n",
    "    ax3.set_xlabel(\"Receptor\"); ax3.set_ylabel(\"Tiempo\"); fig1.colorbar(im2, ax=ax3, fraction=0.046, pad=0.04)\n",
    "\n",
    "    fig1.tight_layout()\n",
    "    fig1.savefig(os.path.join(save_dir, f\"{file_stub}_maps.png\"), dpi=150)\n",
    "    plt.close(fig1)\n",
    "\n",
    "    recs = np.linspace(0, pred_shot.shape[0]-1, num=3, dtype=int)\n",
    "    t = np.arange(pred_shot.shape[1])\n",
    "    fig2 = plt.figure(figsize=(16,4))\n",
    "    for k, r in enumerate(recs):\n",
    "        ax = fig2.add_subplot(1,3,k+1)\n",
    "        ax.plot(t, real_shot[r], label=\"Real\", linewidth=1.5)\n",
    "        ax.plot(t, pred_shot[r], label=\"Predicho\", linewidth=1.2)\n",
    "        ax.set_title(f\"Shot {shot_idx} | Rec {r}\")\n",
    "        ax.set_xlabel(\"Tiempo\"); ax.set_ylabel(\"Amplitud\")\n",
    "        ax.grid(True); ax.legend()\n",
    "    fig2.tight_layout()\n",
    "    fig2.savefig(os.path.join(save_dir, f\"{file_stub}_traces.png\"), dpi=150)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def eval_metrics_removed_shots_only(model, Xte, Yte, removed_idx, device, binf=2):\n",
    "    \"\"\"\n",
    "    Calcula MSE, PSNR, SSIM, SNR SOLO en los shots eliminados (columns S en 0 en Xte),\n",
    "    promediando sobre CRGs de test.\n",
    "    \"\"\"\n",
    "    if removed_idx is None or len(removed_idx) == 0:\n",
    "        return {\"MSE\": None, \"PSNR\": None, \"SSIM\": None, \"SNR\": None}\n",
    "\n",
    "    model.eval()\n",
    "    Htot, S, T = Yte.shape\n",
    "    MSE, PSNR, SSIMg, SNR = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i0 in range(0, Htot, binf):\n",
    "            i1 = min(i0 + binf, Htot)\n",
    "            xb = torch.from_numpy(Xte[i0:i1]).unsqueeze(1).to(device)\n",
    "            yp = model(xb).squeeze(1).cpu().numpy()                \n",
    "            yt = Yte[i0:i1]                                           \n",
    "\n",
    "            for b in range(yp.shape[0]):\n",
    "                ypn = yp[b, removed_idx]  \n",
    "                ytn = yt[b, removed_idx]  \n",
    "                mse = np.mean((ytn - ypn)**2)\n",
    "                amp = np.ptp(ytn) + 1e-8\n",
    "                psn = 20*np.log10(amp / (np.sqrt(mse + 1e-12))) if mse > 0 else float('inf')\n",
    "                ssi = np.mean([ssim(ytn[j], ypn[j], data_range=2) for j in range(ytn.shape[0])])\n",
    "                snr = 10*np.log10((np.mean(ytn**2)+1e-12)/(mse+1e-12))\n",
    "                MSE.append(mse); PSNR.append(psn); SSIMg.append(ssi); SNR.append(snr)\n",
    "\n",
    "            del xb\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    mean = lambda v: float(np.mean(v)) if len(v) else None\n",
    "    return {\"MSE\": mean(MSE), \"PSNR\": mean(PSNR), \"SSIM\": mean(SSIMg), \"SNR\": mean(SNR)}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dict_losses = {}\n",
    "dict_metrics = {}\n",
    "dict_removed_counts = {}\n",
    "\n",
    "for pct in SCENARIOS:\n",
    "    print(f\">>> Escenario {pct}%: preparando datos...\")\n",
    "    Xtr, Xte, Ytr, Yte, shots_eliminados, global_removed = make_subsample_split(\n",
    "        CRG_all, idx_tr, idx_te, pct, seed_base=1000\n",
    "    )\n",
    "\n",
    "    print(f\">>> Escenario {pct}%: entrenando ({EPOCHS} épocas)...\")\n",
    "    model, loss_hist = train_unet_on_crg(Xtr, Ytr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR)\n",
    "    dict_losses[str(pct)] = loss_hist\n",
    "\n",
    "    print(f\">>> Escenario {pct}%: inferencia y guardado de figuras...\")\n",
    "    sc_dir = os.path.join(OUT_DIR, f\"pct_{pct}\")\n",
    "    os.makedirs(sc_dir, exist_ok=True)\n",
    "\n",
    "    shots_elim_sorted = sorted(list(shots_eliminados))\n",
    "    dict_removed_counts[str(pct)] = int(len(shots_elim_sorted))\n",
    "\n",
    "    shots_sel = shots_elim_sorted[:min(3, len(shots_elim_sorted))] if len(shots_elim_sorted) > 0 else []\n",
    "    for s in shots_sel:\n",
    "        viz_shot_real_vs_pred_minibatch(\n",
    "            model, CRG_all, shots_eliminados, s,\n",
    "            save_dir=sc_dir, file_stub=f\"shot_{s}\"\n",
    "        )\n",
    "\n",
    "    metrics = eval_metrics_removed_shots_only(model, Xte, Yte, np.array(shots_elim_sorted, dtype=int), device, binf=2)\n",
    "    dict_metrics[str(pct)] = metrics\n",
    "\n",
    "print(\">>> Guardando gráfico de pérdidas (todos los escenarios)...\")\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "for k in sorted(dict_losses.keys(), key=lambda z: int(z)):\n",
    "    curve = dict_losses[k]\n",
    "    plt.plot(range(1, len(curve)+1), curve, marker='o', label=f\"{k}%\")\n",
    "plt.title(\"Curva de pérdida (1-SSIM) — escenarios 10–90%\")\n",
    "plt.xlabel(\"Época\"); plt.ylabel(\"Pérdida\")\n",
    "plt.grid(True); plt.legend(title=\"Submuestreo\", ncol=3)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_DIR, \"loss_curves_10_90.png\"), dpi=150)\n",
    "plt.close(fig)\n",
    "\n",
    "rows = []\n",
    "for k in sorted(dict_metrics.keys(), key=lambda z: int(z)):\n",
    "    m = dict_metrics[k] or {}\n",
    "    rows.append({\n",
    "        \"pct_removed\": int(k),\n",
    "        \"shots_removed_count\": dict_removed_counts.get(k, np.nan),\n",
    "        \"MSE\": m.get(\"MSE\", None),\n",
    "        \"PSNR\": m.get(\"PSNR\", None),\n",
    "        \"SSIM\": m.get(\"SSIM\", None),\n",
    "        \"SNR\": m.get(\"SNR\", None),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"pct_removed\").replace({None: np.nan})\n",
    "csv_path = os.path.join(OUT_DIR, \"metrics_removed_shots_10_90.csv\")\n",
    "df.to_csv(csv_path, index=False, float_format=\"%.6f\")\n",
    "\n",
    "print(\">>> Listo. Figuras y tabla en:\", OUT_DIR)\n",
    "print(\">>> CSV de métricas:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2053a39",
   "metadata": {},
   "source": [
    "### Submuestreo de shots - capa binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Cargando archivos...\n",
      ">>> Cargados 512 shots.\n",
      ">>> Datos preparados (CRG, normalización, split).\n",
      ">>> Escenario 10%: preparando datos y modelo...\n",
      ">>> Escenario 10%: inferencia, métricas y guardado de figuras...\n",
      ">>> Escenario 20%: preparando datos y modelo...\n",
      ">>> Escenario 20%: inferencia, métricas y guardado de figuras...\n",
      ">>> Escenario 30%: preparando datos y modelo...\n",
      ">>> Escenario 30%: inferencia, métricas y guardado de figuras...\n",
      ">>> Escenario 40%: preparando datos y modelo...\n",
      ">>> Escenario 40%: inferencia, métricas y guardado de figuras...\n",
      ">>> Escenario 50%: preparando datos y modelo...\n",
      ">>> Escenario 50%: inferencia, métricas y guardado de figuras...\n",
      ">>> Escenario 60%: preparando datos y modelo...\n",
      ">>> Escenario 60%: inferencia, métricas y guardado de figuras...\n",
      ">>> Escenario 70%: preparando datos y modelo...\n",
      ">>> Escenario 70%: inferencia, métricas y guardado de figuras...\n",
      ">>> Escenario 80%: preparando datos y modelo...\n",
      ">>> Escenario 80%: inferencia, métricas y guardado de figuras...\n",
      ">>> Escenario 90%: preparando datos y modelo...\n",
      ">>> Escenario 90%: inferencia, métricas y guardado de figuras...\n",
      ">>> Guardando gráfico de pérdidas (todos los escenarios)...\n",
      ">>> Listo.\n",
      ">>> Figuras y NPZ en: /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste\n",
      ">>> Tabla de métricas CSV: /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/metrics_removed_shots_10_90.csv\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob, numpy as np\n",
    "from obspy.io.segy.segy import _read_segy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_msssim import SSIM\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3\"\n",
    "OUT_DIR  = os.path.join(BASE_DIR, \"salidas_crg_shotmask_ste\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "H, W = 512, 4096             \n",
    "BATCH = 1\n",
    "EPOCHS = 40\n",
    "LR = 1e-4\n",
    "GLOBAL_SEED = 42\n",
    "LAMBDA_SPARSITY = 0.1          \n",
    "SCENARIOS = [10,20,30,40,50,60,70,80,90]\n",
    "\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "\n",
    "def norm_trace_lastaxis(x):\n",
    "    m = np.max(np.abs(x), axis=-1, keepdims=True) + 1e-6\n",
    "    return x / m\n",
    "\n",
    "def crop_to_mult8_2d(arr):\n",
    "    S, T = arr.shape[-2], arr.shape[-1]\n",
    "    S8, T8 = (S // 8) * 8, (T // 8) * 8\n",
    "    if S8 != S or T8 != T:\n",
    "        arr = arr[..., :S8, :T8].copy()\n",
    "    return arr\n",
    "\n",
    "def check_divisible_by_8(h, w):\n",
    "    for val, nm in [(h, \"H(shots)\"), (w, \"W(time)\")]:\n",
    "        assert val % 8 == 0, f\"{nm} debe ser múltiplo de 8 para U-Net: {val}\"\n",
    "\n",
    "def tag(fname):\n",
    "    m = re.search(r'shot_(y\\d{2})_', os.path.basename(fname).lower())\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def load_all(base_dir):\n",
    "    pats = [\"shot_y0[1-8]_*.sgy\", \"shot_y0[1-8]_*.segy\"]\n",
    "    files = sorted(sum([glob.glob(os.path.join(base_dir, p)) for p in pats], []))\n",
    "    files = [f for f in files if tag(f) is not None]\n",
    "    arrs = []\n",
    "    for f in files:\n",
    "        st = _read_segy(f, headonly=False)\n",
    "        A = np.array([tr.data for tr in st.traces], dtype=np.float32)  # (N_rec, T)\n",
    "        arrs.append(A)\n",
    "    return np.stack(arrs, 0), files \n",
    "\n",
    "class UNet2DFull(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def blk(cin, cout):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, 3, padding=1),\n",
    "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True),\n",
    "                nn.Conv2d(cout, cout, 3, padding=1),\n",
    "                nn.BatchNorm2d(cout), nn.LeakyReLU(0.01, True)\n",
    "            )\n",
    "        self.e1, self.p1 = blk(1,64), nn.MaxPool2d(2,2)\n",
    "        self.e2, self.p2 = blk(64,128), nn.MaxPool2d(2,2)\n",
    "        self.e3, self.p3 = blk(128,256), nn.MaxPool2d(2,2)\n",
    "        self.bott = blk(256,512)\n",
    "        self.u3 = nn.ConvTranspose2d(512,256,2,2); self.d3 = blk(512,256)\n",
    "        self.u2 = nn.ConvTranspose2d(256,128,2,2); self.d2 = blk(256,128)\n",
    "        self.u1 = nn.ConvTranspose2d(128, 64,2,2); self.d1 = blk(128, 64)\n",
    "        self.out = nn.Conv2d(64,1,1)\n",
    "    def forward(self,x):\n",
    "        e1=self.e1(x); p1=self.p1(e1)\n",
    "        e2=self.e2(p1); p2=self.p2(e2)\n",
    "        e3=self.e3(p2); p3=self.p3(e3)\n",
    "        b=self.bott(p3)\n",
    "        u3=self.u3(b); d3=self.d3(torch.cat([u3, self.crop(e3,u3)],1))\n",
    "        u2=self.u2(d3); d2=self.d2(torch.cat([u2, self.crop(e2,u2)],1))\n",
    "        u1=self.u1(d2); d1=self.d1(torch.cat([u1, self.crop(e1,u1)],1))\n",
    "        return torch.tanh(self.out(d1))\n",
    "    @staticmethod\n",
    "    def crop(a,b):\n",
    "        _,_,h,w=b.shape; _,_,H,W=a.shape\n",
    "        dh,dw=(H-h)//2,(W-w)//2\n",
    "        return a[:,:,dh:dh+h, dw:dw+w]\n",
    "\n",
    "def count_params(model): return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "class BinaryShotMaskSTE(nn.Module):\n",
    "    \"\"\"\n",
    "    Aprende una prob(keep) por SHOT y elimina K = round(frac_remove * S) disparos\n",
    "    (las filas con menor prob(keep)), usando Straight-Through Estimator (STE).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_shots, init_keep_prob=0.9):\n",
    "        super().__init__()\n",
    "        self.n_shots = int(n_shots)\n",
    "        init_keep_prob = float(np.clip(init_keep_prob, 1e-3, 1-1e-3))\n",
    "        init_logit = np.log(init_keep_prob/(1-init_keep_prob))\n",
    "        self.logits = nn.Parameter(torch.full((self.n_shots,), float(init_logit)))\n",
    "        self.frac_remove = 0.10\n",
    "\n",
    "    def set_frac_remove(self, frac):\n",
    "        self.frac_remove = float(np.clip(frac, 0.0, 1.0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, 1, S, T)  -> enmascara la dimensión S (shots)\n",
    "        devuelve: x_masked, probs(sigmoid), hard(0/1 por shot)\n",
    "        \"\"\"\n",
    "        assert x.dim()==4 and x.shape[2]==self.n_shots, f\"Esperaba S={self.n_shots}, got {x.shape}\"\n",
    "        probs = torch.sigmoid(self.logits)            \n",
    "        K = int(round(self.frac_remove * self.n_shots))\n",
    "        if K > 0:\n",
    "            idx_del = torch.topk(probs, K, largest=False).indices\n",
    "            hard = torch.ones_like(probs); hard[idx_del] = 0.0\n",
    "        else:\n",
    "            hard = torch.ones_like(probs)\n",
    "        ste_mask = hard + probs - probs.detach()         \n",
    "        x_masked = x * ste_mask.view(1,1,self.n_shots,1)\n",
    "        return x_masked, probs, hard\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def hard_indices_removed(self):\n",
    "        probs = torch.sigmoid(self.logits)\n",
    "        K = int(round(self.frac_remove * self.n_shots))\n",
    "        if K <= 0: return np.array([], dtype=int)\n",
    "        idx_del = torch.topk(probs, K, largest=False).indices\n",
    "        return idx_del.cpu().numpy()\n",
    "\n",
    "print(\">>> Cargando archivos...\")\n",
    "gathers_shot, file_list = load_all(BASE_DIR)           \n",
    "print(f\">>> Cargados {len(file_list)} shots.\")\n",
    "\n",
    "assert gathers_shot.shape[1] >= H and gathers_shot.shape[2] >= W, \"Dimensiones < H/W\"\n",
    "gathers_shot = gathers_shot[:, :H, :W].copy()\n",
    "\n",
    "CRG_all = np.transpose(gathers_shot, (1, 0, 2)).copy()\n",
    "CRG_all = norm_trace_lastaxis(CRG_all)\n",
    "CRG_all = crop_to_mult8_2d(CRG_all)\n",
    "S8, T8 = CRG_all.shape[1], CRG_all.shape[2]\n",
    "check_divisible_by_8(S8, T8)\n",
    "\n",
    "idx_rec = np.arange(CRG_all.shape[0])\n",
    "idx_tr, idx_te = train_test_split(idx_rec, test_size=0.2, random_state=42, shuffle=True)\n",
    "CRG_tr, CRG_te = CRG_all[idx_tr], CRG_all[idx_te]\n",
    "print(\">>> Datos preparados (CRG, normalización, split).\")\n",
    "\n",
    "def train_unet_with_shotmask(CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR):\n",
    "    \"\"\"\n",
    "    Entrena U-Net con máscara binaria entrenable en dimensión SHOTS (STE).\n",
    "    Loss = (1-SSIM) + lambda_sparsity * (keep_mean - target_keep)^2\n",
    "    \"\"\"\n",
    "    S = CRG_tr.shape[1]\n",
    "    target_keep = 1.0 - (pct/100.0)\n",
    "\n",
    "    Xt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device) \n",
    "    Yt = torch.from_numpy(CRG_tr).unsqueeze(1).to(device)  \n",
    "\n",
    "    loader = DataLoader(TensorDataset(Xt, Yt), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = UNet2DFull().to(device)\n",
    "    mask_layer = BinaryShotMaskSTE(n_shots=S, init_keep_prob=max(0.05, min(0.95, target_keep))).to(device)\n",
    "    mask_layer.set_frac_remove(pct/100.0)\n",
    "\n",
    "    opt = torch.optim.Adam([\n",
    "        {\"params\": model.parameters(), \"lr\": lr},\n",
    "        {\"params\": mask_layer.parameters(), \"lr\": lr}\n",
    "    ])\n",
    "    crit = SSIM(data_range=2.0, size_average=True, channel=1)\n",
    "\n",
    "    loss_hist = []\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        run = 0.0\n",
    "        for xb, yb in loader:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            xb_masked, probs, hard = mask_layer(xb)     \n",
    "            yp = model(xb_masked)\n",
    "            loss_rec = 1 - crit(yp, yb)\n",
    "\n",
    "            keep_mean = torch.sigmoid(mask_layer.logits).mean()\n",
    "            loss_sp = (keep_mean - target_keep) ** 2\n",
    "\n",
    "            loss = loss_rec + LAMBDA_SPARSITY * loss_sp\n",
    "            loss.backward(); opt.step()\n",
    "            run += float(loss.item())\n",
    "        loss_hist.append(run / len(loader))\n",
    "\n",
    "    return model, mask_layer, loss_hist\n",
    "\n",
    "def eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2):\n",
    "    \"\"\"\n",
    "    Métricas SOLO sobre los shots eliminados (filas cero en la entrada por máscara).\n",
    "    Calcula MSE, PSNR, SSIM, SNR promediando sobre CRGs de test y shots eliminados.\n",
    "    \"\"\"\n",
    "    if len(removed_idx) == 0:\n",
    "        return {\"MSE\": None, \"PSNR\": None, \"SSIM\": None, \"SNR\": None}\n",
    "\n",
    "    model.eval()\n",
    "    Htot, S, T = CRG_te.shape\n",
    "    MSE, PSNR, SSIMg, SNR = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i0 in range(0, Htot, binf):\n",
    "            i1 = min(i0 + binf, Htot)\n",
    "            xb_cpu = CRG_te[i0:i1].copy()\n",
    "            xb_cpu[:, removed_idx, :] = 0.0\n",
    "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
    "\n",
    "            yp = model(xb).squeeze(1).cpu().numpy()  \n",
    "            yt = CRG_te[i0:i1]                    \n",
    "\n",
    "            for b in range(yp.shape[0]):\n",
    "                ypn = yp[b, removed_idx]\n",
    "                ytn = yt[b, removed_idx]\n",
    "                mse = np.mean((ytn - ypn)**2)\n",
    "                amp = np.ptp(ytn) + 1e-8\n",
    "                psn = 20*np.log10(amp / (np.sqrt(mse + 1e-12))) if mse > 0 else float('inf')\n",
    "                ssi = np.mean([ssim(ytn[j], ypn[j], data_range=2) for j in range(ytn.shape[0])])\n",
    "                snr = 10*np.log10((np.mean(ytn**2)+1e-12) / (mse+1e-12))\n",
    "                MSE.append(mse); PSNR.append(psn); SSIMg.append(ssi); SNR.append(snr)\n",
    "\n",
    "            del xb\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    mean = lambda v: float(np.mean(v)) if len(v) else None\n",
    "    return {\"MSE\": mean(MSE), \"PSNR\": mean(PSNR), \"SSIM\": mean(SSIMg), \"SNR\": mean(SNR)}\n",
    "\n",
    "def viz_shot_real_vs_pred_minibatch_masked(model, removed_idx, CRG_all, shot_idx,\n",
    "                                           save_dir, file_stub, vmin=-1, vmax=1, binf=2):\n",
    "    \"\"\"\n",
    "    Predice por mini-lotes (receptores) con los MISMOS shots eliminados (removed_idx)\n",
    "    y guarda mapas Predicho/Real/Error + 3 trazas para el shot_idx.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    Htot, S, T = CRG_all.shape\n",
    "    pred_shot = np.zeros((Htot, T), dtype=np.float32)\n",
    "    real_shot = CRG_all[:, shot_idx, :].copy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i0 in range(0, Htot, binf):\n",
    "            i1 = min(i0 + binf, Htot)\n",
    "            xb_cpu = CRG_all[i0:i1].copy()\n",
    "            if len(removed_idx) > 0:\n",
    "                xb_cpu[:, removed_idx, :] = 0.0\n",
    "            xb = torch.from_numpy(xb_cpu).unsqueeze(1).to(device)\n",
    "            yb = model(xb).squeeze(1).cpu().numpy()\n",
    "            pred_shot[i0:i1, :] = yb[:, shot_idx, :]\n",
    "            del xb, yb\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    err = np.abs(pred_shot - real_shot)\n",
    "    fig1 = plt.figure(figsize=(18, 5))\n",
    "    ax1 = fig1.add_subplot(1,3,1)\n",
    "    im0 = ax1.imshow(pred_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title(f\"Predicho — Shot {shot_idx}\")\n",
    "    ax1.set_xlabel(\"Receptor\"); ax1.set_ylabel(\"Tiempo\"); fig1.colorbar(im0, ax=ax1, fraction=0.046, pad=0.04)\n",
    "\n",
    "    ax2 = fig1.add_subplot(1,3,2)\n",
    "    im1 = ax2.imshow(real_shot.T, cmap='gray', aspect='auto', origin='upper', vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title(f\"Real — Shot {shot_idx}\")\n",
    "    ax2.set_xlabel(\"Receptor\"); ax2.set_ylabel(\"Tiempo\"); fig1.colorbar(im1, ax=ax2, fraction=0.046, pad=0.04)\n",
    "\n",
    "    ax3 = fig1.add_subplot(1,3,3)\n",
    "    im2 = ax3.imshow(err.T, cmap='inferno', aspect='auto', origin='upper')\n",
    "    ax3.set_title(\"Error absoluto\")\n",
    "    ax3.set_xlabel(\"Receptor\"); ax3.set_ylabel(\"Tiempo\"); fig1.colorbar(im2, ax=ax3, fraction=0.046, pad=0.04)\n",
    "\n",
    "    fig1.tight_layout()\n",
    "    fig1.savefig(os.path.join(save_dir, f\"{file_stub}_maps.png\"), dpi=150)\n",
    "    plt.close(fig1)\n",
    "\n",
    "    recs = np.linspace(0, pred_shot.shape[0]-1, num=3, dtype=int)\n",
    "    t = np.arange(pred_shot.shape[1])\n",
    "    fig2 = plt.figure(figsize=(16,4))\n",
    "    for k, r in enumerate(recs):\n",
    "        ax = fig2.add_subplot(1,3,k+1)\n",
    "        ax.plot(t, real_shot[r], label=\"Real\", linewidth=1.5)\n",
    "        ax.plot(t, pred_shot[r], label=\"Predicho\", linewidth=1.2)\n",
    "        ax.set_title(f\"Shot {shot_idx} | Rec {r}\")\n",
    "        ax.set_xlabel(\"Tiempo\"); ax.set_ylabel(\"Amplitud\")\n",
    "        ax.grid(True); ax.legend()\n",
    "    fig2.tight_layout()\n",
    "    fig2.savefig(os.path.join(save_dir, f\"{file_stub}_traces.png\"), dpi=150)\n",
    "    plt.close(fig2)\n",
    "\n",
    "def save_mask_bars(removed_idx, S, save_path, height=40, title=None):\n",
    "    mask = np.ones(S, dtype=np.float32)\n",
    "    mask[removed_idx] = 0.0\n",
    "    img = np.ones((height, S), dtype=np.float32)\n",
    "    img[:, mask == 0] = 0.0\n",
    "    fig = plt.figure(figsize=(14, 2.2))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.imshow(img, cmap=\"gray\", aspect=\"auto\", origin=\"upper\", vmin=0, vmax=1)\n",
    "    ax.set_yticks([]); ax.set_xlabel(\"Shot (índice 0..S-1)\")\n",
    "    ax.set_title(title if title else \"Máscara de shots (1 keep / 0 removed)\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(save_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_npz_per_pct(pct, probs, hard, logits, removed_idx, loss_hist, metrics_dict, out_dir):\n",
    "    path = os.path.join(out_dir, f\"run_pct{pct:02d}.npz\")\n",
    "    np.savez_compressed(\n",
    "        path,\n",
    "        probs=np.asarray(probs, dtype=np.float32),\n",
    "        hard=np.asarray(hard, dtype=np.float32),\n",
    "        logits=np.asarray(logits, dtype=np.float32),\n",
    "        removed_idx=np.asarray(removed_idx, dtype=np.int32),\n",
    "        loss_hist=np.asarray(loss_hist, dtype=np.float32),\n",
    "        MSE=(metrics_dict.get(\"MSE\") if metrics_dict else None),\n",
    "        PSNR=(metrics_dict.get(\"PSNR\") if metrics_dict else None),\n",
    "        SSIM=(metrics_dict.get(\"SSIM\") if metrics_dict else None),\n",
    "        SNR=(metrics_dict.get(\"SNR\") if metrics_dict else None),\n",
    "    )\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dict_losses = {}\n",
    "dict_metrics = {}\n",
    "dict_removed_counts = {}\n",
    "\n",
    "for pct in SCENARIOS:\n",
    "    print(f\">>> Escenario {pct}%: preparando datos y modelo...\")\n",
    "    model, mask_layer, loss_hist = train_unet_with_shotmask(CRG_tr, pct, device, epochs=EPOCHS, batch_size=BATCH, lr=LR)\n",
    "    dict_losses[str(pct)] = loss_hist\n",
    "\n",
    "    print(f\">>> Escenario {pct}%: inferencia, métricas y guardado de figuras...\")\n",
    "    removed_idx = mask_layer.hard_indices_removed()\n",
    "    dict_removed_counts[str(pct)] = int(len(removed_idx))\n",
    "    S = CRG_all.shape[1]\n",
    "\n",
    "    sc_dir = os.path.join(OUT_DIR, f\"pct_{pct:02d}\")\n",
    "    os.makedirs(sc_dir, exist_ok=True)\n",
    "\n",
    "    save_mask_bars(removed_idx, S, os.path.join(sc_dir, \"mask_bars.png\"),\n",
    "                   title=f\"Máscara de shots — {pct}% eliminados\")\n",
    "\n",
    "    shots_sel = removed_idx[:min(3, len(removed_idx))] if len(removed_idx) > 0 else []\n",
    "    for s in shots_sel:\n",
    "        viz_shot_real_vs_pred_minibatch_masked(\n",
    "            model, removed_idx, CRG_all, s,\n",
    "            save_dir=sc_dir, file_stub=f\"shot_{s}\"\n",
    "        )\n",
    "\n",
    "    metrics = eval_metrics_removed_shots_only_with_mask(model, CRG_te, removed_idx, device, binf=2)\n",
    "    dict_metrics[str(pct)] = metrics\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs_np = torch.sigmoid(mask_layer.logits).detach().cpu().numpy()\n",
    "        hard_np  = np.ones_like(probs_np, dtype=np.float32); \n",
    "        hard_np[removed_idx] = 0.0\n",
    "        logits_np = mask_layer.logits.detach().cpu().numpy()\n",
    "    save_npz_per_pct(pct, probs_np, hard_np, logits_np, removed_idx, loss_hist, metrics, sc_dir)\n",
    "\n",
    "print(\">>> Guardando gráfico de pérdidas (todos los escenarios)...\")\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "for k in sorted(dict_losses.keys(), key=lambda z: int(z)):\n",
    "    curve = dict_losses[k]\n",
    "    plt.plot(range(1, len(curve)+1), curve, marker='o', label=f\"{k}%\")\n",
    "plt.title(\"Curva de pérdida (1-SSIM + λ·sparsity) — escenarios 10–90% (mask SHOTS)\")\n",
    "plt.xlabel(\"Época\"); plt.ylabel(\"Pérdida\")\n",
    "plt.grid(True); plt.legend(title=\"Submuestreo\", ncol=3)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_DIR, \"loss_curves_shotmask_10_90.png\"), dpi=150)\n",
    "plt.close(fig)\n",
    "\n",
    "rows = []\n",
    "for k in sorted(dict_metrics.keys(), key=lambda z: int(z)):\n",
    "    m = dict_metrics[k] or {}\n",
    "    rows.append({\n",
    "        \"pct_removed\": int(k),\n",
    "        \"shots_removed_count\": dict_removed_counts.get(k, np.nan),\n",
    "        \"MSE\": m.get(\"MSE\", None),\n",
    "        \"PSNR\": m.get(\"PSNR\", None),\n",
    "        \"SSIM\": m.get(\"SSIM\", None),\n",
    "        \"SNR\": m.get(\"SNR\", None),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"pct_removed\").replace({None: np.nan})\n",
    "csv_path = os.path.join(OUT_DIR, \"metrics_removed_shots_10_90.csv\")\n",
    "df.to_csv(csv_path, index=False, float_format=\"%.6f\")\n",
    "\n",
    "print(\">>> Listo.\")\n",
    "print(\">>> Figuras y NPZ en:\", OUT_DIR)\n",
    "print(\">>> Tabla de métricas CSV:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4855f6",
   "metadata": {},
   "source": [
    "### Generación de imagenes de planta - visualizacion de shots submuestreados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6e9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 10% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct10.png\n",
      "[OK] 20% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct20.png\n",
      "[OK] 30% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct30.png\n",
      "[OK] 40% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct40.png\n",
      "[OK] 50% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct50.png\n",
      "[OK] 60% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct60.png\n",
      "[OK] 70% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct70.png\n",
      "[OK] 80% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct80.png\n",
      "[OK] 90% -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/plano_pct90.png\n",
      "[OK] Conteo por línea -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/removed_per_line.csv\n",
      "[OK] Mosaico -> /home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste/planos_planta_8x64/planos_mosaico.png\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, matplotlib.pyplot as plt, pandas as pd\n",
    "\n",
    "NPZ_DIR = \"/home/pc-2/Documents/CAVE_minciencias/utah_model/shot densos 3/salidas_crg_shotmask_ste\"\n",
    "OUT_DIR = os.path.join(NPZ_DIR, \"planos_planta_8x64\")\n",
    "PCTS    = [10,20,30,40,50,60,70,80,90]\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "plt.rcParams[\"figure.dpi\"] = 130\n",
    "\n",
    "LINES = 8          \n",
    "COLS  = 64           \n",
    "S_EXP = LINES * COLS \n",
    "\n",
    "def load_removed_idx(npz_path):\n",
    "    \"\"\"Lee índices eliminados desde un .npz (preferencia: removed_idx, si no, hard==0).\"\"\"\n",
    "    d = np.load(npz_path, allow_pickle=True)\n",
    "    if \"removed_idx\" in d.files:\n",
    "        ridx = np.asarray(d[\"removed_idx\"], dtype=int)\n",
    "    elif \"hard\" in d.files:\n",
    "        hard = np.asarray(d[\"hard\"]).astype(float)\n",
    "        ridx = np.where(hard == 0)[0].astype(int)\n",
    "    else:\n",
    "        raise ValueError(f\"No hay 'removed_idx' ni 'hard' en {npz_path}\")\n",
    "    return np.unique(ridx)\n",
    "\n",
    "def to_plan_matrix(removed_idx, lines=LINES, cols=COLS):\n",
    "    \"\"\"Matriz (lines, cols) con 1=keep, 0=removed.\"\"\"\n",
    "    mat = np.ones((lines, cols), dtype=np.float32)\n",
    "    # sanitiza índices por si acaso\n",
    "    ridx = np.asarray(removed_idx, dtype=int)\n",
    "    ridx = ridx[(ridx >= 0) & (ridx < lines*cols)]\n",
    "    for s in ridx:\n",
    "        r = s // cols\n",
    "        c = s %  cols\n",
    "        mat[r, c] = 0.0\n",
    "    return mat\n",
    "\n",
    "def plot_plan(mat, title, path_png):\n",
    "    \"\"\"Dibuja planta con cuadriculado fino (negro = eliminado).\"\"\"\n",
    "    fig = plt.figure(figsize=(14, 3.8))\n",
    "    ax  = fig.add_subplot(1,1,1)\n",
    "    ax.imshow(mat, cmap=\"gray\", origin=\"upper\", vmin=0, vmax=1, aspect=\"auto\")\n",
    "    ax.set_xticks(np.arange(-.5, mat.shape[1], 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, mat.shape[0], 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"k\", linestyle=\"-\", linewidth=0.2, alpha=0.25)\n",
    "    ax.set_xticks(np.arange(-.5, mat.shape[1], 8), minor=False)\n",
    "    ax.grid(which=\"major\", axis=\"x\", color=\"k\", linestyle=\"-\", linewidth=0.35, alpha=0.35)\n",
    "\n",
    "    ax.set_xlabel(\"Columna de shot (0..63)\")\n",
    "    ax.set_ylabel(\"Línea (0..7)\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path_png, dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "def count_removed_per_line(mat):\n",
    "    return (mat == 0).sum(axis=1)\n",
    "\n",
    "rows_csv = []\n",
    "valid_pcts = []\n",
    "\n",
    "for pct in PCTS:\n",
    "    sub = os.path.join(NPZ_DIR, f\"pct_{pct:02d}\")\n",
    "    candidates = [\n",
    "        os.path.join(sub, f\"run_pct{pct:02d}.npz\"),\n",
    "        os.path.join(sub, f\"run_pct{pct}.npz\"),\n",
    "        os.path.join(sub, f\"run_pct{pct:02d}_ste.npz\"),\n",
    "        os.path.join(sub, f\"run_pct{pct}_ste.npz\"),\n",
    "    ]\n",
    "    npz_path = next((p for p in candidates if os.path.isfile(p)), None)\n",
    "    if npz_path is None:\n",
    "        print(f\"[WARN] No encontré NPZ para {pct}% en {sub}\")\n",
    "        continue\n",
    "\n",
    "    ridx = load_removed_idx(npz_path)\n",
    "\n",
    "    if ridx.size and (ridx.max() >= S_EXP):\n",
    "        print(f\"[WARN] Algún índice ({ridx.max()}) >= {S_EXP}. Ajusta LINES/COLS si tu S != 512.\")\n",
    "\n",
    "    mat = to_plan_matrix(ridx, LINES, COLS)\n",
    "    removed_cnt = int((mat == 0).sum())\n",
    "    keep_cnt    = int((mat == 1).sum())\n",
    "\n",
    "    title   = f\"Plano de shots eliminados — {pct}% (negro = eliminado) | removed={removed_cnt}, keep={keep_cnt}\"\n",
    "    out_png = os.path.join(OUT_DIR, f\"plano_pct{pct:02d}.png\")\n",
    "    plot_plan(mat, title, out_png)\n",
    "    print(f\"[OK] {pct}% -> {out_png}\")\n",
    "\n",
    "    counts = count_removed_per_line(mat)\n",
    "    rows_csv.append({\"pct\": pct, **{f\"line_{i}\": int(c) for i, c in enumerate(counts)}})\n",
    "    valid_pcts.append(pct)\n",
    "\n",
    "if rows_csv:\n",
    "    df = pd.DataFrame(rows_csv).sort_values(\"pct\")\n",
    "    csv_path = os.path.join(OUT_DIR, \"removed_per_line.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"[OK] Conteo por línea -> {csv_path}\")\n",
    "\n",
    "if valid_pcts:\n",
    "    cols = 3\n",
    "    rows = int(np.ceil(len(valid_pcts) / cols))\n",
    "    fig = plt.figure(figsize=(6*cols, 2.8*rows))\n",
    "    for i, pct in enumerate(sorted(valid_pcts)):\n",
    "        sub = os.path.join(NPZ_DIR, f\"pct_{pct:02d}\")\n",
    "        for name in [f\"run_pct{pct:02d}.npz\", f\"run_pct{pct}.npz\", f\"run_pct{pct:02d}_ste.npz\", f\"run_pct{pct}_ste.npz\"]:\n",
    "            npz_path = os.path.join(sub, name)\n",
    "            if os.path.isfile(npz_path):\n",
    "                break\n",
    "        ridx = load_removed_idx(npz_path)\n",
    "        mat  = to_plan_matrix(ridx, LINES, COLS)\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(mat, cmap=\"gray\", origin=\"upper\", vmin=0, vmax=1, aspect=\"auto\")\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(f\"{pct}%\")\n",
    "        ax.set_xticks(np.arange(-.5, mat.shape[1], 8), minor=False)\n",
    "        ax.grid(which=\"major\", axis=\"x\", color=\"k\", linestyle=\"-\", linewidth=0.25, alpha=0.25)\n",
    "\n",
    "    fig.suptitle(\"Planos de shots eliminados por escenario (negro = eliminado)\", y=0.995)\n",
    "    fig.tight_layout()\n",
    "    mosaic_png = os.path.join(OUT_DIR, \"planos_mosaico.png\")\n",
    "    fig.savefig(mosaic_png, dpi=160)\n",
    "    plt.close(fig)\n",
    "    print(f\"[OK] Mosaico -> {mosaic_png}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utah_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
